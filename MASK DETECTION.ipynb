{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 3.1273 - accuracy: 0.5195 - val_loss: 0.7268 - val_accuracy: 0.4375\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.7127 - accuracy: 0.4935 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 3s 358ms/step - loss: 0.7116 - accuracy: 0.5065 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.6874 - accuracy: 0.5325 - val_loss: 0.6851 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 3s 362ms/step - loss: 0.7083 - accuracy: 0.5455 - val_loss: 0.6797 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 3s 366ms/step - loss: 0.6498 - accuracy: 0.7532 - val_loss: 0.6790 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.6167 - accuracy: 0.7662 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.5947 - accuracy: 0.7662 - val_loss: 0.6331 - val_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.5767 - accuracy: 0.7403 - val_loss: 0.6161 - val_accuracy: 0.6875\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 3s 366ms/step - loss: 0.5542 - accuracy: 0.6753 - val_loss: 0.6408 - val_accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.5266 - accuracy: 0.7662 - val_loss: 0.6380 - val_accuracy: 0.6250\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.4956 - accuracy: 0.8052 - val_loss: 0.5934 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.5093 - accuracy: 0.7792 - val_loss: 0.5693 - val_accuracy: 0.6250\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.4798 - accuracy: 0.7662 - val_loss: 0.5850 - val_accuracy: 0.6875\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 3s 359ms/step - loss: 0.4487 - accuracy: 0.8571 - val_loss: 0.6118 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 264ms/step - loss: 0.4244 - accuracy: 0.8182 - val_loss: 0.6413 - val_accuracy: 0.6250\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.4490 - accuracy: 0.7922 - val_loss: 0.6623 - val_accuracy: 0.5625\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 4s 290ms/step - loss: 0.3867 - accuracy: 0.8442 - val_loss: 0.5745 - val_accuracy: 0.6875\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.3902 - accuracy: 0.8442 - val_loss: 0.5136 - val_accuracy: 0.6875\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.3954 - accuracy: 0.8182 - val_loss: 0.4808 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 3s 370ms/step - loss: 0.3589 - accuracy: 0.8831 - val_loss: 0.5287 - val_accuracy: 0.6875\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 3s 375ms/step - loss: 0.3487 - accuracy: 0.8571 - val_loss: 0.6154 - val_accuracy: 0.6250\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 3s 371ms/step - loss: 0.3414 - accuracy: 0.9221 - val_loss: 0.4832 - val_accuracy: 0.6875\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.3016 - accuracy: 0.9500 - val_loss: 0.4089 - val_accuracy: 0.8125\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 3s 357ms/step - loss: 0.2763 - accuracy: 0.9221 - val_loss: 0.5183 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.2723 - accuracy: 0.9375 - val_loss: 0.6368 - val_accuracy: 0.6875\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3024 - accuracy: 0.8831 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 270ms/step - loss: 0.2496 - accuracy: 0.9481 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.2019 - accuracy: 0.9610 - val_loss: 0.4682 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2709 - accuracy: 0.9091 - val_loss: 0.4676 - val_accuracy: 0.8125\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 3s 360ms/step - loss: 0.2308 - accuracy: 0.9351 - val_loss: 0.5463 - val_accuracy: 0.6875\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.2075 - accuracy: 0.9610 - val_loss: 0.4816 - val_accuracy: 0.6875\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.2179 - accuracy: 0.9351 - val_loss: 0.5852 - val_accuracy: 0.5625\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 3s 360ms/step - loss: 0.2217 - accuracy: 0.9351 - val_loss: 0.5706 - val_accuracy: 0.6875\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 4s 294ms/step - loss: 0.2381 - accuracy: 0.9125 - val_loss: 0.5700 - val_accuracy: 0.6250\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1563 - accuracy: 0.9481 - val_loss: 0.3787 - val_accuracy: 0.8125\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.1589 - accuracy: 0.9740 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.1417 - accuracy: 0.9875 - val_loss: 0.4187 - val_accuracy: 0.7500\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1487 - accuracy: 0.9740 - val_loss: 0.5620 - val_accuracy: 0.6875\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 0.1552 - accuracy: 0.9481 - val_loss: 0.4465 - val_accuracy: 0.6875\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 0.1516 - accuracy: 0.9481 - val_loss: 0.8170 - val_accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.1959 - accuracy: 0.9221 - val_loss: 0.4696 - val_accuracy: 0.6875\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 3s 362ms/step - loss: 0.1347 - accuracy: 0.9625 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.1082 - accuracy: 0.9870 - val_loss: 0.6443 - val_accuracy: 0.6875\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.2342 - accuracy: 0.8442 - val_loss: 0.4381 - val_accuracy: 0.8125\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.1844 - accuracy: 0.9481 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.2196 - accuracy: 0.9221 - val_loss: 0.4442 - val_accuracy: 0.7500\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.1216 - accuracy: 0.9870 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 3s 360ms/step - loss: 0.1353 - accuracy: 0.9610 - val_loss: 0.6352 - val_accuracy: 0.6250\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.0955 - accuracy: 0.9740 - val_loss: 0.6806 - val_accuracy: 0.6875\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "                                        ## (64,64,3) -- one kind of Ip format for color imgs\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu')) ## last hidden layer before the Op layer\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "## Pre-processing bfr giving it to the model\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "## Training\n",
    "training_set = train_datagen.flow_from_directory('FaceMask Dataset/Train',target_size = (64, 64),batch_size = 8,class_mode = 'binary')\n",
    "val_set = val_datagen.flow_from_directory('FaceMask Dataset/Val',target_size = (64, 64),batch_size = 8,class_mode = 'binary')\n",
    "\n",
    "model.fit_generator(training_set,steps_per_epoch = 10,epochs = 50,validation_data = val_set,validation_steps = 2)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"Maskmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"Maskmodel.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4096 into shape (64,64,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-549a8576954a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mresized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnormalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresized\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mreshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 4096 into shape (64,64,3)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "json_file = open('Maskmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"Maskmodel.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "## importing the algo and loading the algo into CV using OpenCv \n",
    "haar_cascade = cv2.CascadeClassifier(r'C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml') \n",
    "cam = cv2.VideoCapture(0)\n",
    "labels_dict = {0:'MASKED',1:'NOT MASKED'}\n",
    "color_dict = {0:(0,255,0),1:(0,0,255)}\n",
    "\n",
    "while True:\n",
    "    _,img = cam.read()\n",
    "    greyImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face = haar_cascade.detectMultiScale(greyImg,1.3,4)  ## passing haar cascade frontal face algo with the greyscaled img\n",
    "                                                         ## face will contain values of x,y,w,h --> coordinates of the face\n",
    "    for x,y,w,h in face:\n",
    "        face_img = greyImg[y:y+w,x:x+w]\n",
    "        resized = cv2.resize(face_img,(64,64))\n",
    "        normalized = resized/255.0\n",
    "        reshaped = np.reshape(normalized,(64,64,3))\n",
    "        result = model.predict(reshaped)\n",
    "        \n",
    "        label = np.argmax(result,axis=1)[0]\n",
    "                \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)    #2\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1) \n",
    "        cv2.putText(img,labels_dict[label],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (225,255,255), 2)\n",
    "\n",
    "        \n",
    "    cv2.imshow(\"CameraFeed\",img)\n",
    "    key = cv2.waitKey(10)   \n",
    "    if key == 27:    ## pressing 'esc' key\n",
    "        break\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
